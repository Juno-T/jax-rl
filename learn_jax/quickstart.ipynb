{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import jax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3721109   0.26423115 -0.18252768 -0.7368197  -0.44030377 -0.1521442\n",
      " -0.67135346 -0.5908641   0.73168886  0.5673026 ]\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "x = random.normal(key, (10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.83 ms ± 289 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "size = 3000\n",
    "x = random.normal(key, (size, size), dtype=jnp.float32)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()  # runs on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 177 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.normal(size=(size, size)).astype(np.float32)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42 ms ± 24 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import device_put\n",
    "\n",
    "x = np.random.normal(size=(size, size)).astype(np.float32)\n",
    "x = device_put(x) # put nd array to gpu\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.16 ms ± 3.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = random.normal(key, (1000000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.6 µs ± 512 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "selu_jit = jit(selu) # (@jit decoration) compile multiple operation together with XLA\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661194 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "def sum_logistic(x):\n",
    "  return jnp.sum(1.0 / (1.0 + jnp.exp(-x)))\n",
    "\n",
    "x_small = jnp.arange(3.)\n",
    "derivative_fn = grad(sum_logistic)\n",
    "print(derivative_fn(x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24998187 0.1965761  0.10502338]\n"
     ]
    }
   ],
   "source": [
    "def first_finite_differences(f, x):\n",
    "  eps = 1e-3\n",
    "  return jnp.array([(f(x + eps * v) - f(x - eps * v)) / (2 * eps)\n",
    "                   for v in jnp.eye(len(x))])\n",
    "\n",
    "\n",
    "print(first_finite_differences(sum_logistic, x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0353256\n"
     ]
    }
   ],
   "source": [
    "print(grad(jit(grad(jit(grad(sum_logistic)))))(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "def hessian(fun):\n",
    "  return jit(jacfwd(jacrev(fun)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = random.normal(key, (150, 100))\n",
    "batched_x = random.normal(key, (10, 100))\n",
    "\n",
    "def apply_matrix(v):\n",
    "  return jnp.dot(mat, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naively batched\n",
      "2.06 ms ± 248 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def naively_batched_apply_matrix(v_batched):\n",
    "  return jnp.stack([apply_matrix(v) for v in v_batched])\n",
    "\n",
    "print('Naively batched')\n",
    "%timeit naively_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually batched\n",
      "The slowest run took 4.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "261 µs ± 154 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Manually batched\n",
      "57.8 µs ± 9.76 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def batched_apply_matrix(v_batched):\n",
    "  return jnp.dot(v_batched, mat.T)\n",
    "\n",
    "print('Manually batched')\n",
    "%timeit batched_apply_matrix(batched_x).block_until_ready()\n",
    "\n",
    "@jit\n",
    "def batched_apply_matrix(v_batched):\n",
    "  return jnp.dot(v_batched, mat.T)\n",
    "\n",
    "print('Manually batched')\n",
    "%timeit batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-vectorized with vmap\n",
      "107 µs ± 19.3 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def vmap_batched_apply_matrix(v_batched):\n",
    "  return vmap(apply_matrix)(v_batched)\n",
    "\n",
    "print('Auto-vectorized with vmap')\n",
    "%timeit vmap_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/juno/work/playground/jax-rl/learn_jax.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# JAX: immutable arrays\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000022vscode-remote?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marange(\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000022vscode-remote?line=2'>3</a>\u001b[0m x[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "File \u001b[0;32m~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:6795\u001b[0m, in \u001b[0;36m_unimplemented_setitem\u001b[0;34m(self, i, x)\u001b[0m\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6789'>6790</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unimplemented_setitem\u001b[39m(\u001b[39mself\u001b[39m, i, x):\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6790'>6791</a>\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object does not support item assignment. JAX arrays are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6791'>6792</a>\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mimmutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6792'>6793</a>\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mor another .at[] method: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6793'>6794</a>\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mhttps://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py?line=6794'>6795</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html"
     ]
    }
   ],
   "source": [
    "# JAX: immutable arrays\n",
    "x = jnp.arange(10)\n",
    "x[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10  1  2  3  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "y = x.at[0].set(10)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JAX > LAX > XLA  \n",
    "\">\" = build on, higher level, less strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 4. 4. 4. 4. 4. 4. 4. 4. 3. 1.]\n",
      "[1. 3. 4. 4. 4. 4. 4. 4. 4. 4. 3. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = jnp.array([1, 2, 1])\n",
    "y = jnp.ones(10)\n",
    "print(jnp.convolve(x, y))\n",
    "\n",
    "from jax import lax\n",
    "result = lax.conv_general_dilated(\n",
    "    x.reshape(1, 1, 3).astype(float),  # note: explicit promotion\n",
    "    y.reshape(1, 1, 10),\n",
    "    window_strides=(1,),\n",
    "    padding=[(len(y) - 1, len(y) - 1)])  # equivalent of padding='full' in NumPy\n",
    "print(result[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jit, static&traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(X):\n",
    "  X = X - X.mean(0)\n",
    "  return X / X.std(0)\n",
    "norm_compiled = jit(norm) # require static shape\n",
    "\n",
    "np.random.seed(1701)\n",
    "X = jnp.array(np.random.rand(10000, 10))\n",
    "np.allclose(norm(X), norm_compiled(X), atol=1E-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 µs ± 9.64 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "85.9 µs ± 6.14 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit norm(X).block_until_ready()\n",
    "%timeit norm_compiled(X).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.16529104, -0.5616348 , -0.02158209, -0.37602973,\n",
       "             -0.82070136], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_negatives(x):\n",
    "  return x[x < 0] # not static\n",
    "\n",
    "x = jnp.array(np.random.randn(10))\n",
    "get_negatives(x) # op-by-op mode\n",
    "# jit(get_negatives)(x) # jit mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running f():\n",
      "  x = Traced<ShapedArray(float32[3,4])>with<DynamicJaxprTrace(level=0/1)>\n",
      "  y = Traced<ShapedArray(float32[4])>with<DynamicJaxprTrace(level=0/1)>\n",
      "  result = Traced<ShapedArray(float32[3])>with<DynamicJaxprTrace(level=0/1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 5.291437 ,  2.4938517, 10.846224 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def f(x, y):\n",
    "  print(\"Running f():\")\n",
    "  print(f\"  x = {x}\") # tracer object\n",
    "  print(f\"  y = {y}\")\n",
    "  result = jnp.dot(x + 1, y + 1)\n",
    "  print(f\"  result = {result}\")\n",
    "  return result\n",
    "\n",
    "x = np.random.randn(3, 4)\n",
    "y = np.random.randn(4)\n",
    "f(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.805405  6.7191615 3.2264812]\n",
      "Running f():\n",
      "  x = Traced<ShapedArray(float32[3,4])>with<DynamicJaxprTrace(level=0/1)>\n",
      "  y = Traced<ShapedArray(float32[4,1])>with<DynamicJaxprTrace(level=0/1)>\n",
      "  result = Traced<ShapedArray(float32[3,1])>with<DynamicJaxprTrace(level=0/1)>\n",
      "[[2.3823314]\n",
      " [1.3786898]\n",
      " [1.6461018]]\n"
     ]
    }
   ],
   "source": [
    "x2 = np.random.randn(3, 4)\n",
    "y2 = np.random.randn(4)\n",
    "print(f(x2, y2)) # nothing is printed as it has been compiled. Same input size = no-recompilation\n",
    "print(f(x2, np.random.randn(4,1))) # shape change = recompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[3,4] b:f32[4]. let\n",
       "    c:f32[3,4] = add a 1.0\n",
       "    d:f32[4] = add b 1.0\n",
       "    e:f32[3] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] c d\n",
       "  in (e,) }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import make_jaxpr\n",
    "\n",
    "def f(x, y):\n",
    "  return jnp.dot(x + 1, y + 1)\n",
    "\n",
    "make_jaxpr(f)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConcretizationTypeError",
     "evalue": "Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\nThe problem arose with the `bool` function. \nWhile tracing the function f at /tmp/ipykernel_1479/2422663986.py:1 for jit, this concrete value was not available in Python because it depends on the value of the argument 'neg'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/home/juno/work/playground/jax-rl/learn_jax.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m@jit\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x, neg):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mx \u001b[39mif\u001b[39;00m neg \u001b[39melse\u001b[39;00m x\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=4'>5</a>\u001b[0m f(\u001b[39m1\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[1;32m/home/juno/work/playground/jax-rl/learn_jax.ipynb Cell 31'\u001b[0m in \u001b[0;36mf\u001b[0;34m(x, neg)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m@jit\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x, neg):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mx \u001b[39mif\u001b[39;00m neg \u001b[39melse\u001b[39;00m x\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/work/playground/venv/lib/python3.8/site-packages/jax/core.py:1046\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/core.py?line=1044'>1045</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror\u001b[39m(\u001b[39mself\u001b[39m, arg):\n\u001b[0;32m-> <a href='file:///~/work/playground/venv/lib/python3.8/site-packages/jax/core.py?line=1045'>1046</a>\u001b[0m   \u001b[39mraise\u001b[39;00m ConcretizationTypeError(arg, fname_context)\n",
      "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\nThe problem arose with the `bool` function. \nWhile tracing the function f at /tmp/ipykernel_1479/2422663986.py:1 for jit, this concrete value was not available in Python because it depends on the value of the argument 'neg'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def f(x, neg):\n",
    "  return -x if neg else x # Op flow contain branching that depends on input.\n",
    "\n",
    "f(1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(-1, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(jit, static_argnums=(1,)) # casting arg to static\n",
    "def f(x, neg):\n",
    "  print(neg)\n",
    "  return -x if neg else x\n",
    "\n",
    "f(1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(2, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2, True)\n",
    "f(2, False) # re-compile since static arg is changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "* Just as values can be either static or traced, operations can be static or traced.\n",
    "* Static operations are evaluated at compile-time in Python; traced operations are compiled & evaluated at run-time in XLA.\n",
    "* *Use `numpy` for operations that you want to be static; use `jax.numpy` for operations that you want to be traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=0/1)>\n",
      "x.shape = (2, 3)\n",
      "jnp.array(x.shape).prod() = Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=0/1)>\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "  print(f\"x = {x}\")\n",
    "  print(f\"x.shape = {x.shape}\")\n",
    "  print(f\"jnp.array(x.shape).prod() = {jnp.array(x.shape).prod()}\")\n",
    "  # comment this out to avoid the error:\n",
    "  # return x.reshape(jnp.array(x.shape).prod()) # reshape require static.\n",
    "\n",
    "x = jnp.ones((2, 3))\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "@jit\n",
    "def f(x):\n",
    "  return x.reshape((np.prod(x.shape),)) # reshape require static so use numpy!\n",
    "\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.67 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "54.5 µs ± 41 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "74.3 µs ± 8.51 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    return jnp.dot(x,y)\n",
    "jit_f = jit(f)\n",
    "size = 101\n",
    "x = random.normal(key, (size,size))\n",
    "y = random.normal(key, (size,size))\n",
    "# print(f(x,y))\n",
    "# print(jit_f(x,y))\n",
    "%timeit f(x,y)\n",
    "%timeit jit_f(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/juno/work/playground/jax-rl/learn_jax/quickstart.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/juno/work/playground/jax-rl/learn_jax/quickstart.ipynb#ch0000038vscode-remote?line=0'>1</a>\u001b[0m jax\u001b[39m.\u001b[39mmake_jaxpr(f)(x,y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "jax.make_jaxpr(f)(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax import grad, jit\n",
    "from jax import lax\n",
    "from jax import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['image.interpolation'] = 'nearest'\n",
    "rcParams['image.cmap'] = 'viridis'\n",
    "rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure funcitons\n",
    "JAX transformation and compilation are designed to work only on Python functions that are functionally pure: all the input data is passed through the function parameters, all the results are output through the function results. **A pure function will always return the same result if invoked with the same inputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function\n",
      "First call:  4.0\n",
      "Second call:  5.0\n",
      "Executing function\n",
      "Third call, different type:  [5.]\n"
     ]
    }
   ],
   "source": [
    "def impure_print_side_effect(x):\n",
    "  print(\"Executing function\")  # This is a side-effect \n",
    "  return x\n",
    "\n",
    "# The side-effects appear during the first run  \n",
    "print (\"First call: \", jit(impure_print_side_effect)(4.))\n",
    "\n",
    "# Subsequent runs with parameters of same type and shape may not show the side-effect\n",
    "# This is because JAX now invokes a cached compilation of the function\n",
    "print (\"Second call: \", jit(impure_print_side_effect)(5.))\n",
    "\n",
    "# JAX re-runs the Python function when the type or shape of the argument changes\n",
    "print (\"Third call, different type: \", jit(impure_print_side_effect)(jnp.array([5.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call:  4.0\n",
      "Second call:  5.0\n",
      "Third call, different type:  [14.]\n"
     ]
    }
   ],
   "source": [
    "g = 0.\n",
    "def impure_uses_globals(x):\n",
    "  return x + g\n",
    "\n",
    "# JAX captures the value of the global during the first run\n",
    "print (\"First call: \", jit(impure_uses_globals)(4.))\n",
    "g = 10.  # Update the global\n",
    "\n",
    "# Subsequent runs may silently use the cached value of the globals\n",
    "print (\"Second call: \", jit(impure_uses_globals)(5.))\n",
    "\n",
    "# JAX re-runs the Python function when the type or shape of the argument changes\n",
    "# This will end up reading the latest value of the global\n",
    "print (\"Third call, different type: \", jit(impure_uses_globals)(jnp.array([4.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call:  4.0\n",
      "Saved global:  Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
      "Second call:  4.0\n",
      "Saved global:  10.0\n"
     ]
    }
   ],
   "source": [
    "g = 0.\n",
    "def impure_saves_global(x):\n",
    "  global g\n",
    "  g = x\n",
    "  return x\n",
    "\n",
    "# JAX runs once the transformed function with special Traced values for arguments\n",
    "print (\"First call: \", jit(impure_saves_global)(4.))\n",
    "print (\"Saved global: \", g)  # Saved global has an internal JAX value\n",
    "g = 10. # probably different g from the saved trace\n",
    "print (\"Second call: \", jit(impure_saves_global)(4.))\n",
    "print (\"Saved global: \", g)  # Saved global has an internal JAX value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "def pure_uses_internal_state(x):\n",
    "  state = dict(even=0, odd=0)\n",
    "  for i in range(10):\n",
    "    state['even' if i % 2 == 0 else 'odd'] += x\n",
    "  return state['even'] + state['odd']\n",
    "\n",
    "print(jit(pure_uses_internal_state)(5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect attempts to use iterators with JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.lax as lax\n",
    "from jax import make_jaxpr\n",
    "\n",
    "# lax.fori_loop\n",
    "array = jnp.arange(10)\n",
    "print(lax.fori_loop(0, 10, lambda i,x: x+array[i], 0)) # expected result 45\n",
    "iterator = iter(range(10))\n",
    "print(lax.fori_loop(0, 10, lambda i,x: x+next(iterator), 0)) # unexpected result 0\n",
    "\n",
    "# lax.scan\n",
    "def func11(arr, extra):\n",
    "    ones = jnp.ones(arr.shape)  \n",
    "    def body(carry, aelems):\n",
    "        ae1, ae2 = aelems\n",
    "        return (carry + ae1 * ae2 + extra, carry)\n",
    "    return lax.scan(body, 0., (arr, ones))    \n",
    "make_jaxpr(func11)(jnp.arange(16), 5.)\n",
    "# make_jaxpr(func11)(iter(range(16)), 5.) # throws error\n",
    "\n",
    "# lax.cond\n",
    "array_operand = jnp.array([0.])\n",
    "lax.cond(True, lambda x: x+1, lambda x: x-1, array_operand)\n",
    "iter_operand = iter(range(10))\n",
    "# lax.cond(True, lambda x: next(x)+1, lambda x: next(x)-1, iter_operand) # throws error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Place Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "updated array:\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.zeros((3,3), dtype=np.float32)\n",
    "print(\"original array:\")\n",
    "print(numpy_array)\n",
    "\n",
    "# In place, mutating update\n",
    "numpy_array[1, :] = 1.0\n",
    "print(\"updated array:\")\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
     ]
    }
   ],
   "source": [
    "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
    "\n",
    "# In place update of JAX's array will yield an error!\n",
    "try:\n",
    "  jax_array[1, :] = 1.0\n",
    "except Exception as e:\n",
    "  print(\"Exception {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated array:\n",
      " [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "original array unchanged:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "updated_array = jax_array.at[1, :].set(1.0)\n",
    "print(\"updated array:\\n\", updated_array)\n",
    "print(\"original array unchanged:\\n\", jax_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "new array post-addition:\n",
      "[[1. 1. 1. 8. 8. 8.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 8. 8. 8.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 8. 8. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"original array:\")\n",
    "jax_array = jnp.ones((5, 6))\n",
    "print(jax_array)\n",
    "\n",
    "new_jax_array = jax_array.at[::2, 3:].add(7.)\n",
    "print(\"new array post-addition:\")\n",
    "print(new_jax_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out of bounds indexing\n",
    "If operate at out-of-bounds index:  \n",
    "`Updates` will be skipped  \n",
    "`Retrievals` will be clamped  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception index 11 is out of bounds for axis 0 with size 10\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "try:\n",
    "  np.arange(10)[11]\n",
    "except Exception as e:\n",
    "  print(\"Exception {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(9, dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.arange(10)[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non (j)np array  \n",
    "In functions, always pass (j)np array as arguments. Not python's list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(45, dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works but very bad. Each element in x will be traced separately.\n",
    "def permissive_sum(x):\n",
    "  return jnp.sum(jnp.array(x))\n",
    "\n",
    "x = list(range(10))\n",
    "permissive_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(45, dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do this instead (convert before passing):\n",
    "jnp.sum(jnp.array(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudo random\n",
    "print(np.random.random())\n",
    "print(np.random.random())\n",
    "print(np.random.random())\n",
    "\n",
    "np.random.seed(0)\n",
    "rng_state = np.random.get_state()\n",
    "#print(rng_state)\n",
    "# --> ('MT19937', array([0, 1, 1812433255, 1900727105, 1208447044,\n",
    "#       2481403966, 4042607538,  337614300, ... 614 more numbers..., \n",
    "#       3048484911, 1796872496], dtype=uint32), 624, 0, 0.0)\n",
    "\n",
    "_ = np.random.uniform()\n",
    "rng_state = np.random.get_state()\n",
    "#print(rng_state) \n",
    "# --> ('MT19937', array([2443250962, 1093594115, 1878467924,\n",
    "#       ..., 2648828502, 1678096082], dtype=uint32), 2, 0, 0.0)\n",
    "\n",
    "# Let's exhaust the entropy in this PRNG statevector\n",
    "for i in range(311):\n",
    "  _ = np.random.uniform()\n",
    "rng_state = np.random.get_state()\n",
    "#print(rng_state) \n",
    "# --> ('MT19937', array([2443250962, 1093594115, 1878467924,\n",
    "#       ..., 2648828502, 1678096082], dtype=uint32), 624, 0, 0.0)\n",
    "\n",
    "# Next call iterates the RNG state for a new batch of fake \"entropy\".\n",
    "_ = np.random.uniform()\n",
    "rng_state = np.random.get_state()\n",
    "# print(rng_state) \n",
    "# --> ('MT19937', array([1499117434, 2949980591, 2242547484, \n",
    "#      4162027047, 3277342478], dtype=uint32), 2, 0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JAX *explicit* PRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import random\n",
    "key = random.PRNGKey(0)\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20584226]\n",
      "[0 0]\n",
      "[-0.20584226]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(random.normal(key, shape=(1,)))\n",
    "print(key)\n",
    "# No no no!\n",
    "print(random.normal(key, shape=(1,)))\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old key [0 0]\n",
      "    \\---SPLIT --> new key    [4146024105  967050713]\n",
      "             \\--> new subkey [2718843009 1272950319] --> normal [-1.2515389]\n"
     ]
    }
   ],
   "source": [
    "print(\"old key\", key)\n",
    "key, subkey = random.split(key)\n",
    "normal_pseudorandom = random.normal(subkey, shape=(1,))\n",
    "print(\"    \\---SPLIT --> new key   \", key)\n",
    "print(\"             \\--> new subkey\", subkey, \"--> normal\", normal_pseudorandom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4544677]\n",
      "[-0.49327764]\n",
      "[-0.39947626]\n"
     ]
    }
   ],
   "source": [
    "key, *subkeys = random.split(key, 4)\n",
    "for subkey in subkeys:\n",
    "  print(random.normal(subkey, shape=(1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad to regular python function. Use python control flow.\n",
    "def f(x):\n",
    "  if x < 3:\n",
    "    return 3. * x ** 2\n",
    "  else:\n",
    "    return -4 * x\n",
    "\n",
    "print(grad(f)(2.))  # ok!\n",
    "print(grad(f)(4.))  # ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
      "The problem arose with the `bool` function. \n",
      "While tracing the function f at /tmp/ipykernel_914/2039591909.py:14 for jit, this concrete value was not available in Python because it depends on the value of the argument 'x'.\n",
      "\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\n"
     ]
    }
   ],
   "source": [
    "@jit \n",
    "def f(x): # OK\n",
    "  for i in range(3):\n",
    "    x = 2 * x\n",
    "  return x\n",
    "\n",
    "@jit\n",
    "def g(x): # OK\n",
    "  y = 0.\n",
    "  for i in range(x.shape[0]): # get unroll and turn to trace operation\n",
    "    y = y + x[i]\n",
    "  return y\n",
    "\n",
    "@jit\n",
    "def f(x): # BAD\n",
    "  if x < 3:\n",
    "    return 3. * x ** 2\n",
    "  else:\n",
    "    return -4 * x\n",
    "\n",
    "# This will fail!\n",
    "try:\n",
    "  f(2)\n",
    "except Exception as e:\n",
    "  print(\"Exception {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, jit traces your code on the ShapedArray abstraction level, ... fixed shape and dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "def f(x): # BAD\n",
    "  if x < 3:\n",
    "    return 3. * x ** 2\n",
    "  else:\n",
    "    return -4 * x\n",
    "f = jit(f, static_argnums=(0,))\n",
    "\n",
    "print(f(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(5., dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x, n):\n",
    "  y = 0.\n",
    "  for i in range(n): # \n",
    "    y = y + x[i]\n",
    "  return y\n",
    "\n",
    "f = jit(f, static_argnums=(1,))\n",
    "\n",
    "f(jnp.array([2., 3., 4.]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_fun(length, val):\n",
    "  return jnp.ones((length,)) * val\n",
    "# un-jit'd works fine\n",
    "print(example_fun(5, 4))\n",
    "\n",
    "bad_example_jit = jit(example_fun)\n",
    "# this will fail:\n",
    "try:\n",
    "  print(bad_example_jit(10, 4))\n",
    "except Exception as e:\n",
    "  print(\"Exception {}\".format(e))\n",
    "# static_argnums tells JAX to recompile on changes at these argument positions:\n",
    "good_example_jit = jit(example_fun, static_argnums=(0,))\n",
    "# first compile\n",
    "print(good_example_jit(10, 4))\n",
    "# recompiles\n",
    "print(good_example_jit(5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
      "Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(4, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "  print(x)\n",
    "  y = 2 * x\n",
    "  print(y)\n",
    "  return y\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lax.cond` differentiable\n",
    "\n",
    "`lax.while_loop` fwd-mode-differentiable\n",
    "\n",
    "`lax.fori_loop` fwd-mode-differentiable in general; fwd and rev-mode differentiable if endpoints are static.\n",
    "\n",
    "`lax.scan` differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import lax\n",
    "\n",
    "def cond(pred, true_fun, false_fun, operand):\n",
    "  if pred:\n",
    "    return true_fun(operand)\n",
    "  else:\n",
    "    return false_fun(operand)\n",
    "\n",
    "operand = jnp.array([0.])\n",
    "lax.cond(True, lambda x: x+1, lambda x: x-1, operand)\n",
    "# --> array([1.], dtype=float32)\n",
    "lax.cond(False, lambda x: x+1, lambda x: x-1, operand)\n",
    "# --> array([-1.], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(10, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def while_loop(cond_fun, body_fun, init_val):\n",
    "  val = init_val\n",
    "  while cond_fun(val):\n",
    "    val = body_fun(val)\n",
    "  return val\n",
    "  \n",
    "init_val = 0\n",
    "cond_fun = lambda x: x<10\n",
    "body_fun = lambda x: x+1\n",
    "lax.while_loop(cond_fun, body_fun, init_val)\n",
    "# --> array(10, dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(45, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fori_loop(start, stop, body_fun, init_val):\n",
    "  val = init_val\n",
    "  for i in range(start, stop):\n",
    "    val = body_fun(i, val)\n",
    "  return val\n",
    "\n",
    "  init_val = 0\n",
    "start = 0\n",
    "stop = 10\n",
    "body_fun = lambda i,x: x+i\n",
    "lax.fori_loop(start, stop, body_fun, init_val)\n",
    "# --> array(45, dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c9c7a98df09ad5d09aed9c39f66cd404562c24fcd761bc8bc141afc0ba32c4d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
